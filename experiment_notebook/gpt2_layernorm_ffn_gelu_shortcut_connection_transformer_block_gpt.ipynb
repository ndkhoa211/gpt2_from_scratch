{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# An LLM Architecture (Backbone)"
      ],
      "metadata": {
        "id": "cjrfqGg19--I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's set the configuration:"
      ],
      "metadata": {
        "id": "K0wX2QPw-Kig"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jMThqIsL9CQO"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Placeholder GPT2 Model Architecture Class"
      ],
      "metadata": {
        "id": "nVMi_qlRZkUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DummyGPTModel(nn.Module):\n",
        "  def __init__(self,\n",
        "               config\n",
        "               ):\n",
        "    super().__init__()\n",
        "    self.token_emb = nn.Embedding(config[\"vocab_size\"],\n",
        "                                  config[\"emb_dim\"])\n",
        "    self.position_emb = nn.Embedding(config[\"context_length\"],\n",
        "                                     config[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(config[\"drop_rate\"])\n",
        "\n",
        "    # a placeholder for TransformerBlock\n",
        "    self.transformer_blocks = nn.Sequential(\n",
        "        *[DummyTransformerBlock(config) for _ in range(config[\"n_layers\"])])\n",
        "\n",
        "    # a placeholder for LayerNorm\n",
        "    self.final_norm = DummyLayerNorm(config[\"emb_dim\"])\n",
        "\n",
        "    self.out_head = nn.Linear(config[\"emb_dim\"],\n",
        "                              config[\"vocab_size\"],\n",
        "                              bias=False)\n",
        "\n",
        "  def forward(self, input_token):\n",
        "    batch_size, sequence_length = input_token.shape\n",
        "    token_embeds = self.token_emb(input_token)\n",
        "    position_embeds = self.position_emb(\n",
        "        torch.arange(sequence_length,\n",
        "                     device=input_token.device))\n",
        "    embeds = token_embeds + position_embeds\n",
        "    x = self.drop_emb(embeds)\n",
        "    x = self.transformer_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits\n",
        "\n",
        "\n",
        "# placeholder\n",
        "class DummyTransformerBlock(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "\n",
        "\n",
        "# placeholder\n",
        "class DummyLayerNorm(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x"
      ],
      "metadata": {
        "id": "KaxnqgJS-wT5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup example\n",
        "import tiktoken\n",
        "\n",
        "bpe_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "batch = []\n",
        "\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"Every day holds a\"\n",
        "\n",
        "batch.append(torch.tensor(bpe_tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(bpe_tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch)\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-ezJkcmc7nB",
        "outputId": "c0f4e0a6-fa98-4295-a353-32b98e4e84e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6109, 3626, 6100,  345],\n",
              "        [6109, 1110, 6622,  257]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance\n",
        "torch.manual_seed(211)\n",
        "model = DummyGPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "logits = model(batch)\n",
        "print(\"output shape: \", logits.shape)\n",
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp5JsM-HdeTi",
        "outputId": "f15a66f9-c328-4664-cef6-b24c34197020"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output shape:  torch.Size([2, 4, 50257])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4087, -1.2679,  0.3791,  ...,  0.2964,  0.7493,  0.3239],\n",
              "         [-0.2316,  0.2405, -0.4450,  ...,  0.3991,  0.0026,  0.1075],\n",
              "         [-0.0059,  0.2291, -0.9134,  ..., -1.7940, -0.0074, -0.3314],\n",
              "         [ 1.5600, -0.6588,  0.6326,  ..., -0.5926, -0.8299,  2.0698]],\n",
              "\n",
              "        [[-0.8229, -1.3703,  0.1186,  ...,  0.2430,  0.7330,  0.2529],\n",
              "         [-0.7035, -0.2469, -0.4727,  ...,  0.0581,  0.4801,  0.4443],\n",
              "         [ 0.6955, -0.2896,  0.0219,  ..., -1.2846,  0.4151, -0.0240],\n",
              "         [ 0.5667, -0.1500, -0.0109,  ..., -1.5656, -1.3297,  2.0111]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement LayerNorm"
      ],
      "metadata": {
        "id": "ev8RMHLOeZgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's experiment:"
      ],
      "metadata": {
        "id": "eAddun8Gepo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example setup\n",
        "torch.manual_seed(211)\n",
        "\n",
        "# create 3 training examples with 5 dimensions each\n",
        "batch_example = torch.randn(3, 5)\n",
        "\n",
        "layer = nn.Sequential(nn.Linear(5, 7),\n",
        "                      nn.ReLU())\n",
        "\n",
        "output = layer(batch_example)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPOnv_4vd7ja",
        "outputId": "337fd64c-1964-4524-cc79-29808881df99"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0540, 0.2893, 0.0442, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.8197, 0.1849, 0.1102, 1.7938, 0.3290, 1.2042, 0.0000],\n",
              "        [0.3081, 0.1382, 0.2541, 0.0000, 0.5109, 0.0000, 0.0000]],\n",
              "       grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute mean and variance of each sample\n",
        "mean = output.mean(dim=-1, keepdim=True)\n",
        "var = output.var(dim=-1, keepdim=True)\n",
        "print(\"mean: \", mean)\n",
        "print(\"variance: \", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp4IIwPjfX6W",
        "outputId": "fb38175f-cf12-4aba-dd5e-5cd443ef774d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean:  tensor([[0.1982],\n",
            "        [0.6345],\n",
            "        [0.1730]], grad_fn=<MeanBackward1>)\n",
            "variance:  tensor([[0.1536],\n",
            "        [0.4460],\n",
            "        [0.0383]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's normalize (aka layer normalization) the output:"
      ],
      "metadata": {
        "id": "0-rhSYgqf-jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_output = (output - mean) / torch.sqrt(var)\n",
        "norm_mean = norm_output.mean(dim=-1, keepdim=True)\n",
        "norm_var = norm_output.var(dim=-1, keepdim=True)\n",
        "\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "print(\"normalized mean: \\n\", norm_mean)\n",
        "print(\"normalized variance: \\n\", norm_var)\n",
        "print(\"normalized layer output: \\n\", norm_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLKzU-Jsf1w_",
        "outputId": "06e1d049-d031-4c58-962a-0a376a495560"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normalized mean: \n",
            " tensor([[     0.0000],\n",
            "        [     0.0000],\n",
            "        [    -0.0000]], grad_fn=<MeanBackward1>)\n",
            "normalized variance: \n",
            " tensor([[1.0000],\n",
            "        [1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n",
            "normalized layer output: \n",
            " tensor([[ 2.1836,  0.2324, -0.3930, -0.5058, -0.5058, -0.5058, -0.5058],\n",
            "        [ 0.2772, -0.6733, -0.7852,  1.7360, -0.4575,  0.8530, -0.9502],\n",
            "        [ 0.6897, -0.1777,  0.4139, -0.8838,  1.7256, -0.8838, -0.8838]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement LayerNorm class"
      ],
      "metadata": {
        "id": "zAaAVob4hk33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.epsilon = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1,\n",
        "                unbiased=False, # Bessel's correction (n-1)\n",
        "                keepdim=True)\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.epsilon)\n",
        "    return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "id": "SuIWCiaHgYnF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup example\n",
        "layer_norm = LayerNorm(emb_dim=5)\n",
        "layer_norm_output = layer_norm(batch_example)\n",
        "mean = layer_norm_output.mean(dim=-1, keepdim=True)\n",
        "var = layer_norm_output.var(dim=-1, unbiased=False, keepdim=True)\n",
        "\n",
        "print(\"normalized mean: \\n\", mean)\n",
        "print(\"normalized variance: \\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5HDk-driSaW",
        "outputId": "52216825-99a7-4d99-f6d2-755edede5bf8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normalized mean: \n",
            " tensor([[    -0.0000],\n",
            "        [    -0.0000],\n",
            "        [    -0.0000]], grad_fn=<MeanBackward1>)\n",
            "normalized variance: \n",
            " tensor([[1.0000],\n",
            "        [1.0000],\n",
            "        [0.9999]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement a FFN With GELU Activations"
      ],
      "metadata": {
        "id": "yVz_hlRtjOpm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GC3RkaKBjF-h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}