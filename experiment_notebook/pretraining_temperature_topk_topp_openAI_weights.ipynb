{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Mg5Qe7UvWbXw"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "notebook_start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "id": "zI1PlAAFX0iZ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrain on Unlabled Data"
      ],
      "metadata": {
        "id": "MXE6No3lWw_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Generative Text Models"
      ],
      "metadata": {
        "id": "OyJRHCpE9XFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ch04 import GPT2Model\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 256,  # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}\n",
        "torch.manual_seed(211)\n",
        "model = GPT2Model(GPT_CONFIG_124M)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XOTLL9LW3yL",
        "outputId": "5c95888e-9029-420a-803f-12763a0846cf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Model(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (position_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (transformer_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Utility Functions For Text To Token ID Conversion"
      ],
      "metadata": {
        "id": "tk8umwaXfuEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "from ch04 import generate_text_simple\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "  # turn the list of token IDs into tensor with batch dimension\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(encoded_tensor, tokenizer):\n",
        "  # turn tensor without batch dimension to list\n",
        "  token_ids = encoded_tensor.squeeze(0).tolist()\n",
        "  text = tokenizer.decode(token_ids)\n",
        "  return text"
      ],
      "metadata": {
        "id": "8KHAff--W3vr"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example setup\n",
        "start_context = \"In the midst of winter, I found\"\n",
        "bpe_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(model=model,\n",
        "                                 input_batch=text_to_token_ids(start_context,\n",
        "                                                               bpe_tokenizer),\n",
        "                                 max_new_tokens=10,\n",
        "                                 context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        "                                 )\n",
        "\n",
        "print(\"output text: \\n\", token_ids_to_text(token_ids, bpe_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45RaFxH1W3tR",
        "outputId": "c80ba878-d044-476a-e3cb-945668cb7258"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output text: \n",
            " In the midst of winter, I found gluten primarily220 specificity Manufacttions Pictures SiberiaCongress Ess\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate The Text Generation Loss\n",
        "\n",
        "```\n",
        "logits -> probabilities -> target probabilities -> log probabilities -> average log probability -> negative average log probability (i.e. cross entropy loss)\n",
        "```"
      ],
      "metadata": {
        "id": "_LtK-oxVihS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's experiment on a simple example:"
      ],
      "metadata": {
        "id": "ggsy3zwSjHxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example\n",
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
      ],
      "metadata": {
        "id": "7z1lxD6bW3rC"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute logits\n",
        "with torch.no_grad():\n",
        "  logits = model(inputs)\n",
        "\n",
        "# compute probas\n",
        "probas = torch.softmax(logits, dim=-1)\n",
        "print(\"probas shape: \", probas.shape)\n",
        "\n",
        "# compute argmax and retrieve the token ID with highest probas\n",
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"token IDs shape: \", token_ids.shape)\n",
        "print(\"token IDs: \\n\", token_ids)\n",
        "\n",
        "# convert token IDs into text\n",
        "print(f\"target batch: {token_ids_to_text(targets[0], bpe_tokenizer)}\")\n",
        "print(f\"predicted batch: {token_ids_to_text(token_ids[0].flatten(), bpe_tokenizer)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbmWF-ZKW3ob",
        "outputId": "6befe6ff-4dc8-49b0-9fbd-a613398fbea6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probas shape:  torch.Size([2, 3, 50257])\n",
            "token IDs shape:  torch.Size([2, 3, 1])\n",
            "token IDs: \n",
            " tensor([[[26079],\n",
            "         [46561],\n",
            "         [31436]],\n",
            "\n",
            "        [[29764],\n",
            "         [46155],\n",
            "         [45644]]])\n",
            "target batch:  effort moves you\n",
            "predicted batch: ergy digsCVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve target token ID probas for each batch\n",
        "text_id = 0\n",
        "target_probas_1 = probas[text_id,\n",
        "                         [0, 1, 2],\n",
        "                         targets[text_id]]\n",
        "print(\"target probas: \", target_probas_1)\n",
        "\n",
        "text_id = 1\n",
        "target_probas_2 = probas[text_id,\n",
        "                         [0, 1, 2],\n",
        "                         targets[text_id]]\n",
        "print(\"target probas: \", target_probas_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJvun0FeW3mA",
        "outputId": "ee3b1828-c935-4218-b8c3-1a8247d8f43e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target probas:  tensor([5.8695e-06, 1.1964e-05, 2.3211e-05])\n",
            "target probas:  tensor([1.7885e-05, 1.1387e-05, 1.7034e-05])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute log probabilities\n",
        "log_probas = torch.log(torch.cat([target_probas_1, target_probas_2]))\n",
        "print(\"log probas: \", log_probas)\n",
        "\n",
        "# compute average log probability\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(\"average log probas: \", avg_log_probas)\n",
        "\n",
        "# compute negative average log probability\n",
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(\"negative average log probas: \", neg_avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7ZwTx-_W3ji",
        "outputId": "e76fd556-ec3e-49c7-b264-25216ef57ab9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log probas:  tensor([-12.0457, -11.3336, -10.6709, -10.9315, -11.3831, -10.9803])\n",
            "average log probas:  tensor(-11.2242)\n",
            "negative average log probas:  tensor(11.2242)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use pytorch `cross_entropy` function:"
      ],
      "metadata": {
        "id": "-0kQKUyJozDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example setup\n",
        "print(\"logits shape: \", logits.shape)\n",
        "print(\"targets shape: \", targets.shape)\n",
        "\n",
        "# flatten the tensor before plug into cross_entropy\n",
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "print(\"flatten logits shape: \", logits_flat.shape)\n",
        "print(\"flatten targets shape: \", targets_flat.shape)\n",
        "\n",
        "# compute loss\n",
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(\"loss: \", loss)\n",
        "print(\"loss as float: \", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ikrjXV0W3hQ",
        "outputId": "b8ae7dd3-7ecc-4a50-c6d0-7f87fbe9524d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits shape:  torch.Size([2, 3, 50257])\n",
            "targets shape:  torch.Size([2, 3])\n",
            "flatten logits shape:  torch.Size([6, 50257])\n",
            "flatten targets shape:  torch.Size([6])\n",
            "loss:  tensor(11.2242)\n",
            "loss as float:  11.2241849899292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating The Training And Validation Set Losses"
      ],
      "metadata": {
        "id": "ZoPMNwDNpje-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "file_path = \"the-verdict.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "\n",
        "total_characters = len(text)\n",
        "total_tokens = len(bpe_tokenizer.encode(text))\n",
        "print(f\"total characters: {total_characters}\")\n",
        "print(f\"total tokens: {total_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wvZNR1XW3ew",
        "outputId": "6d78e1a5-bf6e-4885-e3e7-64b9989082f8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total characters: 20479\n",
            "total tokens: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split\n",
        "train_ratio = 0.90\n",
        "split_id = int(train_ratio * len(text))\n",
        "train_text = text[:split_id]\n",
        "val_text = text[split_id:]"
      ],
      "metadata": {
        "id": "UzbRgEydW3cU"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloaders\n",
        "from ch02 import create_dataloader_V1\n",
        "torch.manual_seed(211)\n",
        "\n",
        "\n",
        "train_dataloader = create_dataloader_V1(text=train_text,\n",
        "                                        batch_size=2,\n",
        "                                        context_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "                                        stride=GPT_CONFIG_124M['context_length'],\n",
        "                                        shuffle=True,\n",
        "                                        drop_last=True,\n",
        "                                        num_workers=0)\n",
        "\n",
        "val_dataloader = create_dataloader_V1(text=val_text,\n",
        "                                      batch_size=2,\n",
        "                                      context_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "                                      stride=GPT_CONFIG_124M['context_length'],\n",
        "                                      shuffle=False,\n",
        "                                      drop_last=False,\n",
        "                                      num_workers=0)"
      ],
      "metadata": {
        "id": "iTDFK8swW3Zt"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "\n",
        "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the training loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"increase the `training_ratio`\")\n",
        "\n",
        "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the validation loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"decrease the `training_ratio`\")"
      ],
      "metadata": {
        "id": "wKzog3NaW3XA"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train loader:\")\n",
        "for x, y in train_dataloader:\n",
        "  print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nval loader:\")\n",
        "for x, y in val_dataloader:\n",
        "  print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCJn0rNQW3Ul",
        "outputId": "ea29e6a9-41b3-429a-a4ea-f280c3bb1314"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "val loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create an utility function to calculate the cross entropy loss of a given batch returned via the training and validation loader:"
      ],
      "metadata": {
        "id": "eVUhWKt9uPRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch,\n",
        "                    target_batch,\n",
        "                    model,\n",
        "                    device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1),\n",
        "                                           target_batch.flatten())\n",
        "  return loss"
      ],
      "metadata": {
        "id": "mVuvzi8rW3Sb"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we use the above funtion to create a function to compute the training and validation losses:"
      ],
      "metadata": {
        "id": "h8ex3s1pu54s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(dataloader,\n",
        "                     model,\n",
        "                     device,\n",
        "                     num_batches=None):\n",
        "  total_loss = 0.\n",
        "  if len(dataloader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(dataloader)\n",
        "  else:\n",
        "    # reduce the number of batches to match the total number of batches in the data loader\n",
        "    # if num_batches exceeds the number of batches in the data loader\n",
        "    num_batches = min(num_batches, len(dataloader))\n",
        "  for i, (input_batch, target_batch) in enumerate(dataloader):\n",
        "    if i < num_batches:\n",
        "      loss = calc_loss_batch(input_batch,\n",
        "                             target_batch,\n",
        "                             model,\n",
        "                             device)\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss / num_batches"
      ],
      "metadata": {
        "id": "xr3Q7qboW3P4"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute losses!!!"
      ],
      "metadata": {
        "id": "KfiIulECyykj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "compute_loss_start_time = time.time()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_dataloader,\n",
        "                                model,\n",
        "                                device)\n",
        "  val_loss = calc_loss_loader(val_dataloader,\n",
        "                              model,\n",
        "                              device)\n",
        "\n",
        "print(f\"train loss: {train_loss:.4f}\")\n",
        "print(f\"validation loss: {val_loss:.4f}\")\n",
        "\n",
        "\n",
        "compute_loss_end_time = time.time()\n",
        "runtime_in_seconds = compute_loss_end_time - compute_loss_start_time\n",
        "# format as minutes and seconds\n",
        "minutes, seconds = divmod(runtime_in_seconds, 60)\n",
        "print(f\"compute_loss runtime: {int(minutes)} min {seconds:.2f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_4klJ6_W3Ni",
        "outputId": "33567d89-7c84-4971-bfba-16a07c29186f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 10.9759\n",
            "validation loss: 11.0311\n",
            "compute_loss runtime: 0 min 0.73 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training An LLM"
      ],
      "metadata": {
        "id": "XXLpa82X0BrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's implement a training function:"
      ],
      "metadata": {
        "id": "Rp60IL3D1Sic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model,\n",
        "                       train_loader,\n",
        "                       val_loader,\n",
        "                       optimizer,\n",
        "                       device,\n",
        "                       num_epochs,\n",
        "                       eval_freq,\n",
        "                       eval_iter,\n",
        "                       start_context,\n",
        "                       tokenizer):\n",
        "\n",
        "  # initialize lists to track losses and tokens seen\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  track_tokens_seen = []\n",
        "  token_seen = 0\n",
        "  global_step = -1\n",
        "\n",
        "  # main training loop - iterate over training epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # iterate over batches in each training epoch\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      # reset loss gradients from previous batch iteration\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # calculate loss on current batch\n",
        "      loss = calc_loss_batch(input_batch,\n",
        "                             target_batch,\n",
        "                             model,\n",
        "                             device)\n",
        "\n",
        "      # backward pass to calculate loss gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # update model weights using loss gradients\n",
        "      optimizer.step()\n",
        "      token_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "\n",
        "      # optional evaluation step\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model,\n",
        "                                              train_loader,\n",
        "                                              val_loader,\n",
        "                                              device,\n",
        "                                              eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(token_seen)\n",
        "        # print training and evaluation set loss\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "              f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "    # generative sample text for visual inspection\n",
        "    generate_and_print_sample(model,\n",
        "                              tokenizer,\n",
        "                              device,\n",
        "                              start_context)\n",
        "\n",
        "  return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model,\n",
        "                    train_loader,\n",
        "                    val_loader,\n",
        "                    device,\n",
        "                    eval_iter):\n",
        "  # set model to evaluation mode\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # calculate loss\n",
        "    train_loss = calc_loss_loader(train_loader,\n",
        "                                  model,\n",
        "                                  device,\n",
        "                                  num_batches=eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader,\n",
        "                                model,\n",
        "                                device,\n",
        "                                num_batches=eval_iter)\n",
        "\n",
        "  # set model bacl to training mode\n",
        "  model.train()\n",
        "  return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model,\n",
        "                              tokenizer,\n",
        "                              device,\n",
        "                              start_context):\n",
        "  # set model to evaluation mode\n",
        "  model.eval()\n",
        "  context_size = model.position_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text_simple(model=model,\n",
        "                                     input_batch=encoded,\n",
        "                                     max_new_tokens=50,\n",
        "                                     context_size=context_size)\n",
        "  decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "  print(decoded_text.replace(\"\\n\", \" \")) # compact print format\n",
        "  # set model bacl to training mode\n",
        "  model.train()"
      ],
      "metadata": {
        "id": "18JgciImW3K5"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the LLM:"
      ],
      "metadata": {
        "id": "coJDLqIc6FFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "training_start_time = time.time()\n",
        "\n",
        "torch.manual_seed(211)\n",
        "model = GPT2Model(GPT_CONFIG_124M).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                              lr=0.0004,\n",
        "                              weight_decay=0.1)\n",
        "num_epochs = 20\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(model=model,\n",
        "                                                             train_loader=train_dataloader,\n",
        "                                                             val_loader=val_dataloader,\n",
        "                                                             optimizer=optimizer,\n",
        "                                                             device=device,\n",
        "                                                             num_epochs=num_epochs,\n",
        "                                                             eval_freq=5,\n",
        "                                                             eval_iter=5,\n",
        "                                                             start_context=\"In the midst of winter, I found\",\n",
        "                                                             tokenizer=bpe_tokenizer)\n",
        "\n",
        "\n",
        "training_end_time = time.time()\n",
        "runtime_in_seconds = training_end_time - training_start_time\n",
        "# format as minutes and seconds\n",
        "minutes, seconds = divmod(runtime_in_seconds, 60)\n",
        "print(f\"device: {device}\")\n",
        "print(f\"training runtime: {int(minutes)} min {seconds:.2f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2Vl0vO3W3I6",
        "outputId": "7c42671e-3ff0-4ca4-cb58-e01bb7a316b2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.793, Val loss 10.015\n",
            "Ep 1 (Step 000005): Train loss 8.116, Val loss 8.308\n",
            "In the midst of winter, I found the                                                 \n",
            "Ep 2 (Step 000010): Train loss 6.760, Val loss 7.085\n",
            "Ep 2 (Step 000015): Train loss 6.054, Val loss 6.605\n",
            "In the midst of winter, I found the, and, and, the, the, and, and, and, the, and, the the the the, the, and the, and, the the the, the the the the, the the the the the, the, the\n",
            "Ep 3 (Step 000020): Train loss 7.540, Val loss 9.204\n",
            "Ep 3 (Step 000025): Train loss 5.570, Val loss 6.454\n",
            "In the midst of winter, I found, and, and I was, and the.                                        \n",
            "Ep 4 (Step 000030): Train loss 5.501, Val loss 6.621\n",
            "Ep 4 (Step 000035): Train loss 5.269, Val loss 6.500\n",
            "In the midst of winter, I found the with the I had I had \" had the I had the I had \" I had the I had the with the and I had the with the with the with the with the I had the and I had the he was to the with the with\n",
            "Ep 5 (Step 000040): Train loss 4.665, Val loss 6.396\n",
            "In the midst of winter, I found, and, and I had been a little.                                        \n",
            "Ep 6 (Step 000045): Train loss 4.258, Val loss 6.330\n",
            "Ep 6 (Step 000050): Train loss 3.921, Val loss 6.350\n",
            "In the midst of winter, I found-rooms, I said--I have the picture--the and I felt him, I felt, I felt to see his pictures, and I had been the picture--his I had been his pictures--and it, I felt to see it,\n",
            "Ep 7 (Step 000055): Train loss 3.282, Val loss 6.238\n",
            "Ep 7 (Step 000060): Train loss 2.656, Val loss 6.290\n",
            "In the midst of winter, I found-rooms, I had been his pictures. Gisburn. Gisburn's an!     \"I didn't you know; and I had been the fact of his pictures--I didn't--as it, I had\n",
            "Ep 8 (Step 000065): Train loss 2.243, Val loss 6.284\n",
            "Ep 8 (Step 000070): Train loss 1.736, Val loss 6.264\n",
            "In the midst of winter, I found--and that he was him, I had the last word. Gisburn's an awful simple's \"Yes--his just he had the house.\"    \"I had been the man of the hour. The younger artist was said\n",
            "Ep 9 (Step 000075): Train loss 1.550, Val loss 6.306\n",
            "Ep 9 (Step 000080): Train loss 1.186, Val loss 6.408\n",
            "In the midst of winter, I found me--I glanced after him, a good fellow--and. Gisburn's past!      \"Oh, the window-curtains, as I had been the man of the hour. The younger artist was said\n",
            "Ep 10 (Step 000085): Train loss 0.909, Val loss 6.443\n",
            "In the midst of winter, I found me, for he was \"interesting\": on that point I could have given Miss Croft the fact, becoming the man of the moment--as Jack himself, one might put it, had been the man of the hour. The younger artist was said\n",
            "Ep 11 (Step 000090): Train loss 0.675, Val loss 6.442\n",
            "Ep 11 (Step 000095): Train loss 0.449, Val loss 6.482\n",
            "In the midst of winter, I found me--quite insensible to the irony. Gisburn's: make yourself comfortable--and here are the cigars you like.\"                        \n",
            "Ep 12 (Step 000100): Train loss 0.354, Val loss 6.577\n",
            "Ep 12 (Step 000105): Train loss 0.316, Val loss 6.696\n",
            "In the midst of winter, I found me, for he answered with a deprecating laugh: \"Yes--and by me!\"  \"I what a degree he had the window-curtains, moved aside a _jardiniere_ full of pink azaleas\n",
            "Ep 13 (Step 000110): Train loss 0.235, Val loss 6.744\n",
            "Ep 13 (Step 000115): Train loss 0.179, Val loss 6.809\n",
            "In the midst of winter, I found me, for he answered with a deprecating laugh: \"Yes--she's an awful simpleton, you know, and threw back the same quality as his pictures--since he liked his ease--because he didn't want to go on painting\n",
            "Ep 14 (Step 000120): Train loss 0.171, Val loss 6.838\n",
            "Ep 14 (Step 000125): Train loss 0.146, Val loss 6.907\n",
            "In the midst of winter, I found me I felt able to face the irony. She wanted him vindicated--and by me!\"  He laughed again, and, on a later day, one might put it, married a rich widow, and established himself in a villa on\n",
            "Ep 15 (Step 000130): Train loss 0.134, Val loss 6.940\n",
            "In the midst of winter, I found me brush.\"  And his tone told me in a flash that he never thought of anything else.  I moved away, instinctively embarrassed by my unexpected discovery; and as I turned, my eye fell on a small picture above the mantel\n",
            "Ep 16 (Step 000135): Train loss 0.120, Val loss 6.993\n",
            "Ep 16 (Step 000140): Train loss 0.113, Val loss 7.059\n",
            "In the midst of winter, I found me still a cheap genius--I told Mrs. Stroud so when she began to stammer something about her poverty. I remember getting off a prodigious phrase about the honour being _mine_--oh, I was princely, beaming\n",
            "Ep 17 (Step 000145): Train loss 0.090, Val loss 7.085\n",
            "Ep 17 (Step 000150): Train loss 0.109, Val loss 7.084\n",
            "In the midst of winter, I found me I felt able to face the irony. She wanted him vindicated--and by me!\" I was hear that, in the height of his head to look up at the honour being _mine_--oh, I was princely, my dear\n",
            "Ep 18 (Step 000155): Train loss 0.068, Val loss 7.127\n",
            "Ep 18 (Step 000160): Train loss 0.049, Val loss 7.102\n",
            "In the midst of winter, I found me, for he answered with a deprecating laugh: \"Yes--she's past!  Mrs. It was just because she was _not_ interesting--if I may be pardoned the bull--ah, poor Stroud! She\n",
            "Ep 19 (Step 000165): Train loss 0.059, Val loss 7.099\n",
            "Ep 19 (Step 000170): Train loss 0.051, Val loss 7.152\n",
            "In the midst of winter, I found--forming, as it were, struck by his last word. Poor Jack Gisburn! The women had made him--it was fitting that they should mourn him. Among his own sex fewer regrets were heard, and in his own trade hardly a\n",
            "Ep 20 (Step 000175): Train loss 0.049, Val loss 7.136\n",
            "In the midst of winter, I found-stream stroke. Gisburn--as such--had not existed till nearly a year after Jack's resolve had been taken. It might be that he had married her--since he liked his ease--because he didn't want to go on painting\n",
            "device: cuda\n",
            "training runtime: 1 min 0.29 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot a loss graph:"
      ],
      "metadata": {
        "id": "q3hEb6gFACj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epoch_seen,\n",
        "                tokens_seen,\n",
        "                train_losses,\n",
        "                val_losses):\n",
        "  fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "  # plot training and validation loss against epochs\n",
        "  ax1.plot(epoch_seen, train_losses, label=\"Training Loss\")\n",
        "  ax1.plot(epoch_seen, val_losses, linestyle=\"-.\", label=\"Validation Loss\")\n",
        "  ax1.set_xlabel(\"Epoch\")\n",
        "  ax1.set_ylabel(\"Loss\")\n",
        "  ax1.legend(loc=\"upper right\")\n",
        "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True)) # only show integer labels on x-axis\n",
        "\n",
        "  # create a second x-axis for token seen\n",
        "  ax2 = ax1.twiny() # create a second x-axis that shares the same y-axis\n",
        "  ax2.plot(tokens_seen, train_losses, alpha=0) # invisible plot for aligning ticks\n",
        "  ax2.set_xlabel(\"Tokens Seen\")\n",
        "\n",
        "  fig.tight_layout() # asjust layput to make room\n",
        "  plt.savefig(\"loss_plot.pdf\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "E-h7BHpEW3GZ",
        "outputId": "c2dc8eb4-2ce2-47a5-abc9-76c8cf280d6d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoding Strategies To Control Randomness"
      ],
      "metadata": {
        "id": "zT4B20o6Cih_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JBQnMpP1W3EO"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8l-cdD0W3B2"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_7y2fU0IW2__"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZCyEBuvWcwX"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FwDdXVoWWcuS"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CfNIf-HUWcsD"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pSLAhk0DWcp6"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CsHWnRl5Wcnx"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KKjK21vaWcig"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_end_time = time.time()\n",
        "runtime_in_seconds = notebook_end_time - notebook_start_time\n",
        "\n",
        "# format as minutes and seconds\n",
        "minutes, seconds = divmod(runtime_in_seconds, 60)\n",
        "print(f\"Notebook runtime: {int(minutes)} min {seconds:.2f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUEJEePKWcfs",
        "outputId": "982546f0-4e67-42e7-d606-eed293be2339"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook runtime: 4 min 58.12 sec\n"
          ]
        }
      ]
    }
  ]
}