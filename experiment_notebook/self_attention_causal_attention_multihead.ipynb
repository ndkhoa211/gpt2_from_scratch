{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Attention Mechanism"
      ],
      "metadata": {
        "id": "BW3wN4mJi7o5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Self-Attention Without Trainable Weights"
      ],
      "metadata": {
        "id": "fEY69Bqy4CnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a simple example:"
      ],
      "metadata": {
        "id": "1CxYGxrh3dzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ug_J_HJidIZ",
        "outputId": "6ee95386-5337-4a0b-9450-cb4c51b7fae1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")\n",
        "\n",
        "inputs.shape # [token, embedding_dim]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = inputs[1] # 2nd input token is the query\n",
        "attention_scores_2 = torch.empty(inputs.shape[0])\n",
        "\n",
        "# compute attention scores\n",
        "for i, input_embedding in enumerate(inputs):\n",
        "  attention_scores_2[i] = torch.dot(query_2, input_embedding)\n",
        "\n",
        "attention_scores_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLnYvh-v3kU8",
        "outputId": "9a829fc7-8088-40ae-d50f-e6e5049e9414"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention weights\n",
        "attention_weights_2 = torch.softmax(attention_scores_2, dim=0)\n",
        "\n",
        "print(\"attention weights: \", attention_weights_2)\n",
        "print(\"sum:\", attention_weights_2.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD3Se2hJ4SBy",
        "outputId": "f43adc3f-63a1-44e5-eb87-cdbdb53e6d67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention weights:  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vector\n",
        "context_vector_2 = torch.zeros(inputs.shape[1])\n",
        "\n",
        "for i, input_embedding in enumerate(inputs):\n",
        "  context_vector_2 += attention_weights_2[i] * input_embedding\n",
        "\n",
        "context_vector_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNIHqOdF5-Iv",
        "outputId": "9d8fe842-2c25-43d9-ead9-08c82ab11a52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4419, 0.6515, 0.5683])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute for all queries simultaneously using matrices:"
      ],
      "metadata": {
        "id": "7p-k7peP7tbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention scores\n",
        "attention_scores = inputs @ inputs.T\n",
        "attention_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JukK-r-f7qo7",
        "outputId": "681509d6-8584-4b45-a54b-ff02840e6b0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
              "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
              "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
              "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
              "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
              "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention weights\n",
        "attention_weights = torch.softmax(attention_scores, dim=-1)\n",
        "print(\"row sums:\", attention_weights.sum(dim=-1))\n",
        "attention_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcgW42Fh6in7",
        "outputId": "f681375b-2fb6-4e1a-c38f-2b591b27fd7e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
              "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
              "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
              "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
              "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
              "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vectors\n",
        "context_vectors = attention_weights @ inputs\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icOWE4Nd9EHS",
        "outputId": "4690e112-7459-4f7d-a12a-50509e4c7af5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4421, 0.5931, 0.5790],\n",
              "        [0.4419, 0.6515, 0.5683],\n",
              "        [0.4431, 0.6496, 0.5671],\n",
              "        [0.4304, 0.6298, 0.5510],\n",
              "        [0.4671, 0.5910, 0.5266],\n",
              "        [0.4177, 0.6503, 0.5645]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Self-Attention with Trainable Weights"
      ],
      "metadata": {
        "id": "DHO01f949axm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bRd0eUAT9TNs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}