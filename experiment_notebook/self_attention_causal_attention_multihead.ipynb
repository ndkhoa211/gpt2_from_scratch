{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Attention Mechanism"
      ],
      "metadata": {
        "id": "BW3wN4mJi7o5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Self-Attention Without Trainable Weights"
      ],
      "metadata": {
        "id": "fEY69Bqy4CnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a simple example:"
      ],
      "metadata": {
        "id": "1CxYGxrh3dzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ug_J_HJidIZ",
        "outputId": "6ee95386-5337-4a0b-9450-cb4c51b7fae1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")\n",
        "\n",
        "inputs.shape # [token, embedding_dim]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = inputs[1] # 2nd input token is the query\n",
        "attention_scores_2 = torch.empty(inputs.shape[0])\n",
        "\n",
        "# compute attention scores\n",
        "for i, input_embedding in enumerate(inputs):\n",
        "  attention_scores_2[i] = torch.dot(query_2, input_embedding)\n",
        "\n",
        "attention_scores_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLnYvh-v3kU8",
        "outputId": "9a829fc7-8088-40ae-d50f-e6e5049e9414"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention weights\n",
        "attention_weights_2 = torch.softmax(attention_scores_2, dim=0)\n",
        "\n",
        "print(\"attention weights: \", attention_weights_2)\n",
        "print(\"sum:\", attention_weights_2.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD3Se2hJ4SBy",
        "outputId": "f43adc3f-63a1-44e5-eb87-cdbdb53e6d67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention weights:  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vector\n",
        "context_vector_2 = torch.zeros(inputs.shape[1])\n",
        "\n",
        "for i, input_embedding in enumerate(inputs):\n",
        "  context_vector_2 += attention_weights_2[i] * input_embedding\n",
        "\n",
        "context_vector_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNIHqOdF5-Iv",
        "outputId": "9d8fe842-2c25-43d9-ead9-08c82ab11a52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4419, 0.6515, 0.5683])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute for all queries simultaneously using matrices:"
      ],
      "metadata": {
        "id": "7p-k7peP7tbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention scores\n",
        "attention_scores = inputs @ inputs.T\n",
        "attention_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JukK-r-f7qo7",
        "outputId": "681509d6-8584-4b45-a54b-ff02840e6b0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
              "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
              "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
              "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
              "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
              "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention weights\n",
        "attention_weights = torch.softmax(attention_scores, dim=-1)\n",
        "print(\"row sums:\", attention_weights.sum(dim=-1))\n",
        "attention_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcgW42Fh6in7",
        "outputId": "f681375b-2fb6-4e1a-c38f-2b591b27fd7e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
              "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
              "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
              "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
              "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
              "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vectors\n",
        "context_vectors = attention_weights @ inputs\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icOWE4Nd9EHS",
        "outputId": "4690e112-7459-4f7d-a12a-50509e4c7af5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4421, 0.5931, 0.5790],\n",
              "        [0.4419, 0.6515, 0.5683],\n",
              "        [0.4431, 0.6496, 0.5671],\n",
              "        [0.4304, 0.6298, 0.5510],\n",
              "        [0.4671, 0.5910, 0.5266],\n",
              "        [0.4177, 0.6503, 0.5645]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Self-Attention with Trainable Weights"
      ],
      "metadata": {
        "id": "DHO01f949axm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute KVQ vectors\n"
      ],
      "metadata": {
        "id": "LXBMeitE-fzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define some variables\n",
        "x_2 = inputs[1] # 2nd input token is the query\n",
        "input_embedding_dim = inputs.shape[1] # dim=3\n",
        "output_embedding_dim = 5 # output dim=2"
      ],
      "metadata": {
        "id": "bRd0eUAT9TNs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create KVQ matrices:"
      ],
      "metadata": {
        "id": "KPAW_klv-8Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(211)\n",
        "W_query = torch.nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim),\n",
        "                             requires_grad=False)\n",
        "W_key = torch.nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim),\n",
        "                           requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim),\n",
        "                             requires_grad=False)"
      ],
      "metadata": {
        "id": "eGxQrpiX-6IR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# project x_2 into KVQ spaces\n",
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "\n",
        "print(\"query_2:\", query_2)\n",
        "print(\"key_2:\", key_2)\n",
        "print(\"value_2:\", value_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN1pUVyB_cmv",
        "outputId": "7bdd3311-667f-48cd-a9ed-74bc31ffcb93"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_2: tensor([0.3530, 0.8074, 0.7720, 0.9246, 0.7118])\n",
            "key_2: tensor([0.6885, 0.4568, 1.4283, 1.4383, 1.2989])\n",
            "value_2: tensor([1.2123, 0.6055, 1.0735, 1.3861, 1.5435])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute all the projected keys and values:"
      ],
      "metadata": {
        "id": "FvmuD6rbAGm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "\n",
        "print(\"keys:\", keys)\n",
        "print(\"values:\", values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugizxMq7AGF1",
        "outputId": "f914fe1d-0d45-49ee-e26e-13df8e5cb6c4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys: tensor([[0.4207, 0.2279, 1.2477, 0.9477, 0.7168],\n",
            "        [0.6885, 0.4568, 1.4283, 1.4383, 1.2989],\n",
            "        [0.6925, 0.4572, 1.4219, 1.4353, 1.2789],\n",
            "        [0.3541, 0.2496, 0.7168, 0.7615, 0.7592],\n",
            "        [0.5700, 0.3358, 0.9077, 0.9768, 0.5587],\n",
            "        [0.3412, 0.2621, 0.8338, 0.8443, 0.9977]])\n",
            "values: tensor([[0.6973, 0.4836, 1.1020, 1.0985, 0.9538],\n",
            "        [1.2123, 0.6055, 1.0735, 1.3861, 1.5435],\n",
            "        [1.2069, 0.6000, 1.0771, 1.3826, 1.5277],\n",
            "        [0.6661, 0.3190, 0.4886, 0.7061, 0.8630],\n",
            "        [0.7701, 0.3332, 0.8395, 0.9301, 0.8138],\n",
            "        [0.7621, 0.3945, 0.4978, 0.7934, 1.0709]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the attention scores of x_2\n",
        "attention_scores_2 = query_2 @ keys.T\n",
        "attention_scores_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUsvmIFV_4Ss",
        "outputId": "431156b4-757e-4cde-a6d8-4105cfe0b685"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.6821, 3.9688, 3.9486, 2.1243, 2.4738, 2.4665])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention weights\n",
        "keys_embedding_dim = keys.shape[-1]\n",
        "attention_weights_2 = torch.softmax(attention_scores_2 / keys_embedding_dim**0.5, dim=-1)\n",
        "attention_weights_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cNV7cnIBYTi",
        "outputId": "c04aa753-0ad8-4353-e2bd-3f5c4a2c707e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1401, 0.2491, 0.2468, 0.1092, 0.1276, 0.1272])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vectors\n",
        "context_vector_2 = attention_weights_2 @ values\n",
        "context_vector_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1D0yBaICQDL",
        "outputId": "fbb91b3e-d310-44ed-c9b7-4021b0dec293"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9655, 0.4942, 0.9114, 1.1371, 1.2295])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement a Self-Attention Class"
      ],
      "metadata": {
        "id": "7QXvRnhOCwL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttentionV1(nn.Module):\n",
        "  def __init__(self, input_embedding_dim, output_embedding_dim):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim))\n",
        "    self.W_key = nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim))\n",
        "    self.W_value = nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    keys = inputs @ self.W_key\n",
        "    values = inputs @ self.W_value\n",
        "    queries = inputs @ self.W_query\n",
        "\n",
        "    attention_scores = queries @ keys.T\n",
        "    attention_weights = torch.softmax(\n",
        "        attention_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    context_vectors = attention_weights @ values\n",
        "    return context_vectors"
      ],
      "metadata": {
        "id": "JRybDDwICduL"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(211)\n",
        "sa_v1 = SelfAttentionV1(input_embedding_dim, output_embedding_dim)\n",
        "context_vectors = sa_v1(inputs)\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwsYMYeXMVRR",
        "outputId": "24a82dba-029e-4a75-c001-29b75230d675"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9414, 0.4835, 0.8960, 1.1131, 1.1991],\n",
              "        [0.9655, 0.4942, 0.9114, 1.1371, 1.2295],\n",
              "        [0.9641, 0.4936, 0.9103, 1.1357, 1.2278],\n",
              "        [0.9298, 0.4771, 0.8825, 1.0980, 1.1843],\n",
              "        [0.9173, 0.4713, 0.8726, 1.0845, 1.1688],\n",
              "        [0.9458, 0.4847, 0.8955, 1.1156, 1.2045]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ## Implement a Self-Attention Class With Linear Layers"
      ],
      "metadata": {
        "id": "b-gNMn1AMuNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionV2(nn.Module):\n",
        "  def __init__(self, input_embedding_dim, output_embedding_dim, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                             bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                             bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                             bias=qkv_bias)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    keys = self.W_key(inputs)\n",
        "    values = self.W_value(inputs)\n",
        "    queries = self.W_query(inputs)\n",
        "\n",
        "    attention_scores = queries @ keys.T\n",
        "    attention_weights = torch.softmax(\n",
        "        attention_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    context_vectors = attention_weights @ values\n",
        "    return context_vectors"
      ],
      "metadata": {
        "id": "-Bj72H8ZMcbg"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(211)\n",
        "sa_v2 = SelfAttentionV2(input_embedding_dim, output_embedding_dim)\n",
        "context_vectors = sa_v2(inputs)\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOaIC_yxNXA-",
        "outputId": "de19b458-35a8-498a-f206-d6f490562c65"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2783,  0.4747, -0.4724, -0.0341,  0.3074],\n",
              "        [ 0.2768,  0.4746, -0.4740, -0.0356,  0.3078],\n",
              "        [ 0.2768,  0.4747, -0.4741, -0.0353,  0.3078],\n",
              "        [ 0.2798,  0.4775, -0.4724, -0.0288,  0.3086],\n",
              "        [ 0.2779,  0.4780, -0.4733, -0.0269,  0.3090],\n",
              "        [ 0.2799,  0.4764, -0.4724, -0.0316,  0.3081]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2M2C9oZwNZV_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}