{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Attention Mechanism"
      ],
      "metadata": {
        "id": "BW3wN4mJi7o5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Self-Attention Without Trainable Weights"
      ],
      "metadata": {
        "id": "fEY69Bqy4CnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a simple example:"
      ],
      "metadata": {
        "id": "1CxYGxrh3dzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ug_J_HJidIZ",
        "outputId": "a7d22b42-a22a-4364-8f2f-f4fa06d1ad75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")\n",
        "\n",
        "inputs.shape # [token, embedding_dim]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = inputs[1] # 2nd input token is the query\n",
        "attention_scores_2 = torch.empty(inputs.shape[0])\n",
        "\n",
        "# compute attention scores\n",
        "for i, input_embedding in enumerate(inputs):\n",
        "  attention_scores_2[i] = torch.dot(query_2, input_embedding)\n",
        "\n",
        "attention_scores_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLnYvh-v3kU8",
        "outputId": "ad492dd2-7d25-4f8e-cc5e-55c266d8fde2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention weights\n",
        "attention_weights_2 = torch.softmax(attention_scores_2, dim=0)\n",
        "\n",
        "print(\"attention weights: \", attention_weights_2)\n",
        "print(\"sum:\", attention_weights_2.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD3Se2hJ4SBy",
        "outputId": "0d813c14-f133-4f55-8e10-67cca4be5fc2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention weights:  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vector\n",
        "context_vector_2 = torch.zeros(inputs.shape[1])\n",
        "\n",
        "for i, input_embedding in enumerate(inputs):\n",
        "  context_vector_2 += attention_weights_2[i] * input_embedding\n",
        "\n",
        "context_vector_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNIHqOdF5-Iv",
        "outputId": "911b6f39-4349-49b0-aec8-72af31365816"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4419, 0.6515, 0.5683])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute for all queries simultaneously using matrices:"
      ],
      "metadata": {
        "id": "7p-k7peP7tbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention scores\n",
        "attention_scores = inputs @ inputs.T\n",
        "attention_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JukK-r-f7qo7",
        "outputId": "af4abf71-8db2-4ae9-d9d7-90faac014f2a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
              "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
              "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
              "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
              "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
              "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention weights\n",
        "attention_weights = torch.softmax(attention_scores, dim=-1)\n",
        "print(\"row sums:\", attention_weights.sum(dim=-1))\n",
        "attention_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcgW42Fh6in7",
        "outputId": "8f582cf5-91df-4fc3-fc75-0b70ccf36bf6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
              "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
              "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
              "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
              "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
              "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vectors\n",
        "context_vectors = attention_weights @ inputs\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icOWE4Nd9EHS",
        "outputId": "18c6e002-beae-47b7-dffa-ba62869a7c65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4421, 0.5931, 0.5790],\n",
              "        [0.4419, 0.6515, 0.5683],\n",
              "        [0.4431, 0.6496, 0.5671],\n",
              "        [0.4304, 0.6298, 0.5510],\n",
              "        [0.4671, 0.5910, 0.5266],\n",
              "        [0.4177, 0.6503, 0.5645]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Self-Attention with Trainable Weights"
      ],
      "metadata": {
        "id": "DHO01f949axm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute KVQ vectors\n"
      ],
      "metadata": {
        "id": "LXBMeitE-fzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define some variables\n",
        "x_2 = inputs[1] # 2nd input token is the query\n",
        "input_embedding_dim = inputs.shape[1] # dim=3\n",
        "output_embedding_dim = 5 # output dim=2"
      ],
      "metadata": {
        "id": "bRd0eUAT9TNs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create KVQ matrices:"
      ],
      "metadata": {
        "id": "KPAW_klv-8Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(211)\n",
        "W_query = torch.nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim),\n",
        "                             requires_grad=False)\n",
        "W_key = torch.nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim),\n",
        "                           requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim),\n",
        "                             requires_grad=False)"
      ],
      "metadata": {
        "id": "eGxQrpiX-6IR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# project x_2 into KVQ spaces\n",
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "\n",
        "print(\"query_2:\", query_2)\n",
        "print(\"key_2:\", key_2)\n",
        "print(\"value_2:\", value_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN1pUVyB_cmv",
        "outputId": "d4b838ce-a384-4c7a-e1bb-c39ca399c619"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_2: tensor([0.3530, 0.8074, 0.7720, 0.9246, 0.7118])\n",
            "key_2: tensor([0.6885, 0.4568, 1.4283, 1.4383, 1.2989])\n",
            "value_2: tensor([1.2123, 0.6055, 1.0735, 1.3861, 1.5435])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute all the projected keys and values:"
      ],
      "metadata": {
        "id": "FvmuD6rbAGm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "\n",
        "print(\"keys:\", keys)\n",
        "print(\"values:\", values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugizxMq7AGF1",
        "outputId": "5cf09536-3e53-47c8-fb2c-b307f06e99b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys: tensor([[0.4207, 0.2279, 1.2477, 0.9477, 0.7168],\n",
            "        [0.6885, 0.4568, 1.4283, 1.4383, 1.2989],\n",
            "        [0.6925, 0.4572, 1.4219, 1.4353, 1.2789],\n",
            "        [0.3541, 0.2496, 0.7168, 0.7615, 0.7592],\n",
            "        [0.5700, 0.3358, 0.9077, 0.9768, 0.5587],\n",
            "        [0.3412, 0.2621, 0.8338, 0.8443, 0.9977]])\n",
            "values: tensor([[0.6973, 0.4836, 1.1020, 1.0985, 0.9538],\n",
            "        [1.2123, 0.6055, 1.0735, 1.3861, 1.5435],\n",
            "        [1.2069, 0.6000, 1.0771, 1.3826, 1.5277],\n",
            "        [0.6661, 0.3190, 0.4886, 0.7061, 0.8630],\n",
            "        [0.7701, 0.3332, 0.8395, 0.9301, 0.8138],\n",
            "        [0.7621, 0.3945, 0.4978, 0.7934, 1.0709]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the attention scores of x_2\n",
        "attention_scores_2 = query_2 @ keys.T\n",
        "attention_scores_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUsvmIFV_4Ss",
        "outputId": "26a4dea8-de93-4218-d936-f53665a8cab9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.6821, 3.9688, 3.9486, 2.1243, 2.4738, 2.4665])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention weights\n",
        "keys_embedding_dim = keys.shape[-1]\n",
        "attention_weights_2 = torch.softmax(attention_scores_2 / keys_embedding_dim**0.5, dim=-1)\n",
        "attention_weights_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cNV7cnIBYTi",
        "outputId": "a550e93b-69ae-41b9-b611-08f1c1270ede"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1401, 0.2491, 0.2468, 0.1092, 0.1276, 0.1272])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute context vectors\n",
        "context_vector_2 = attention_weights_2 @ values\n",
        "context_vector_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1D0yBaICQDL",
        "outputId": "cff36ed4-8d20-4b01-8ca9-45c17913d5a2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9655, 0.4942, 0.9114, 1.1371, 1.2295])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement a Self-Attention Class"
      ],
      "metadata": {
        "id": "7QXvRnhOCwL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttentionV1(nn.Module):\n",
        "  def __init__(self, input_embedding_dim, output_embedding_dim):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim))\n",
        "    self.W_key = nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim))\n",
        "    self.W_value = nn.Parameter(torch.rand(input_embedding_dim, output_embedding_dim))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    keys = inputs @ self.W_key\n",
        "    values = inputs @ self.W_value\n",
        "    queries = inputs @ self.W_query\n",
        "\n",
        "    attention_scores = queries @ keys.T\n",
        "    attention_weights = torch.softmax(\n",
        "        attention_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    context_vectors = attention_weights @ values\n",
        "    return context_vectors"
      ],
      "metadata": {
        "id": "JRybDDwICduL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(211)\n",
        "sa_v1 = SelfAttentionV1(input_embedding_dim, output_embedding_dim)\n",
        "context_vectors = sa_v1(inputs)\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwsYMYeXMVRR",
        "outputId": "358a2dc9-0b4f-45c5-c10e-8ffd4fe3783f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9414, 0.4835, 0.8960, 1.1131, 1.1991],\n",
              "        [0.9655, 0.4942, 0.9114, 1.1371, 1.2295],\n",
              "        [0.9641, 0.4936, 0.9103, 1.1357, 1.2278],\n",
              "        [0.9298, 0.4771, 0.8825, 1.0980, 1.1843],\n",
              "        [0.9173, 0.4713, 0.8726, 1.0845, 1.1688],\n",
              "        [0.9458, 0.4847, 0.8955, 1.1156, 1.2045]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement a Self-Attention Class With Linear Layers"
      ],
      "metadata": {
        "id": "b-gNMn1AMuNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionV2(nn.Module):\n",
        "  def __init__(self, input_embedding_dim, output_embedding_dim, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                             bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                             bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                             bias=qkv_bias)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    keys = self.W_key(inputs)\n",
        "    values = self.W_value(inputs)\n",
        "    queries = self.W_query(inputs)\n",
        "\n",
        "    attention_scores = queries @ keys.T\n",
        "    attention_weights = torch.softmax(\n",
        "        attention_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    context_vectors = attention_weights @ values\n",
        "    return context_vectors"
      ],
      "metadata": {
        "id": "-Bj72H8ZMcbg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(211)\n",
        "sa_v2 = SelfAttentionV2(input_embedding_dim, output_embedding_dim)\n",
        "context_vectors = sa_v2(inputs)\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOaIC_yxNXA-",
        "outputId": "200d9a6b-2b44-4050-b34a-4684311b4558"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2783,  0.4747, -0.4724, -0.0341,  0.3074],\n",
              "        [ 0.2768,  0.4746, -0.4740, -0.0356,  0.3078],\n",
              "        [ 0.2768,  0.4747, -0.4741, -0.0353,  0.3078],\n",
              "        [ 0.2798,  0.4775, -0.4724, -0.0288,  0.3086],\n",
              "        [ 0.2779,  0.4780, -0.4733, -0.0269,  0.3090],\n",
              "        [ 0.2799,  0.4764, -0.4724, -0.0316,  0.3081]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Causal Attention Mask"
      ],
      "metadata": {
        "id": "K8WP_-3pObGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "queries = sa_v2.W_query(inputs)\n",
        "keys = sa_v2.W_key(inputs)\n",
        "attention_scores = queries @ keys.T\n",
        "attention_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M2C9oZwNZV_",
        "outputId": "811c7dd6-66e2-43c2-a91a-ae579bc3e2cc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1403, -0.0855, -0.1058,  0.0263, -0.4402,  0.2156],\n",
              "        [-0.1708, -0.0352, -0.0575,  0.0688, -0.4432,  0.2793],\n",
              "        [-0.1734, -0.0347, -0.0566,  0.0683, -0.4349,  0.2748],\n",
              "        [-0.0777, -0.0100, -0.0220,  0.0403, -0.2321,  0.1540],\n",
              "        [-0.1706, -0.0153, -0.0234,  0.0407, -0.1629,  0.1161],\n",
              "        [-0.0599, -0.0171, -0.0340,  0.0472, -0.3295,  0.2079]],\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the lower triangle matrix of 1's\n",
        "context_length = inputs.shape[0]\n",
        "masked_matrix = torch.triu(torch.ones(context_length, context_length),\n",
        "                           diagonal=1\n",
        "                           )\n",
        "print(masked_matrix)\n",
        "print(masked_matrix.bool())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw22moHsPRW9",
        "outputId": "a9af9b51-f76d-44ec-c5af-1ecd12e67504"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0.]])\n",
            "tensor([[False,  True,  True,  True,  True,  True],\n",
            "        [False, False,  True,  True,  True,  True],\n",
            "        [False, False, False,  True,  True,  True],\n",
            "        [False, False, False, False,  True,  True],\n",
            "        [False, False, False, False, False,  True],\n",
            "        [False, False, False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform masked attention: fill upper triangle of attention_scores with -inf\n",
        "masked_attention_scores = attention_scores.masked_fill(\n",
        "    masked_matrix.bool(), -torch.inf)\n",
        "masked_attention_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx-j4d0gPuV9",
        "outputId": "57c669ba-1829-417e-afed-231193bdc42b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1403,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
              "        [-0.1708, -0.0352,    -inf,    -inf,    -inf,    -inf],\n",
              "        [-0.1734, -0.0347, -0.0566,    -inf,    -inf,    -inf],\n",
              "        [-0.0777, -0.0100, -0.0220,  0.0403,    -inf,    -inf],\n",
              "        [-0.1706, -0.0153, -0.0234,  0.0407, -0.1629,    -inf],\n",
              "        [-0.0599, -0.0171, -0.0340,  0.0472, -0.3295,  0.2079]],\n",
              "       grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute masked attention weights\n",
        "masked_attention_weights = torch.softmax(\n",
        "    masked_attention_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "masked_attention_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kORX3A3kP-2p",
        "outputId": "e7d12dfd-3fb8-4845-dc82-9a193cf0f902"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4848, 0.5152, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3208, 0.3413, 0.3380, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2433, 0.2508, 0.2494, 0.2565, 0.0000, 0.0000],\n",
              "        [0.1907, 0.2045, 0.2037, 0.2097, 0.1914, 0.0000],\n",
              "        [0.1641, 0.1673, 0.1660, 0.1722, 0.1455, 0.1850]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masked Attention Weights + Dropout"
      ],
      "metadata": {
        "id": "QK7WgxdlS0Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(211)\n",
        "dropout_05 = torch.nn.Dropout(p=0.5)\n",
        "dropout_05(masked_attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKINtb4JSod-",
        "outputId": "bd6412fe-3901-469f-8fe3-9778db3ad48e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.9697, 1.0303, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.6415, 0.6826, 0.6759, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.5016, 0.4989, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3815, 0.4089, 0.4075, 0.4193, 0.0000, 0.0000],\n",
              "        [0.0000, 0.3346, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement a Causual Attention Class"
      ],
      "metadata": {
        "id": "vYklxXgVTZoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch setup\n",
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jky4e_iBTFkW",
        "outputId": "580e04df-80d2-4ca5-8e0a-66022d5221d2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_embedding_dim,\n",
        "               output_embedding_dim,\n",
        "               context_length,\n",
        "               dropout,\n",
        "               qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.output_embedding_dim = output_embedding_dim\n",
        "    self.W_query = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                             bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                             bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                             bias=qkv_bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        \"mask\",\n",
        "        torch.triu(torch.ones(context_length, context_length),\n",
        "                                            diagonal=1))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    batch, num_tokens, input_embedding_dim = inputs.shape\n",
        "    keys = self.W_key(inputs)\n",
        "    values = self.W_value(inputs)\n",
        "    queries = self.W_query(inputs)\n",
        "\n",
        "    attention_scores = queries @ keys.transpose(1, 2)\n",
        "    attention_scores.masked_fill_(\n",
        "        self.mask.bool()[:num_tokens, :num_tokens], - torch.inf)\n",
        "    masked_attention_weight = torch.softmax(\n",
        "        attention_scores / (keys.shape[-1]**0.5),\n",
        "        dim=-1)\n",
        "    masked_attention_dropout_weight = self.dropout(masked_attention_weight)\n",
        "\n",
        "    context_vector = masked_attention_dropout_weight @ values\n",
        "    return context_vector"
      ],
      "metadata": {
        "id": "vu82Uxw4T1qS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance\n",
        "torch.manual_seed(211)\n",
        "context_length = batch.shape[1]\n",
        "ca = CausalAttention(input_embedding_dim=input_embedding_dim,\n",
        "                     output_embedding_dim=output_embedding_dim,\n",
        "                     context_length=context_length,\n",
        "                     dropout=0.2)\n",
        "context_vectors = ca(batch)\n",
        "print(\"context_vector shape: \", context_vectors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTjmgbV9ir6e",
        "outputId": "fc1f0e9d-c030-47da-ca8f-b03e4a25641e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_vector shape:  torch.Size([2, 6, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Head Attention"
      ],
      "metadata": {
        "id": "Dmo8EJwejpUT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LH9s883cjY2c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}